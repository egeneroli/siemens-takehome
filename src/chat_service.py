"""
chat_service.py

This module contains the ChatService class which is responsible for handling chat interactions
using the LangChain framework and Google Generative AI.
"""

import os
from langchain.chains import ConversationChain, LLMChain
from langchain.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate
from langchain_google_genai.chat_models import ChatGoogleGenerativeAI
from config import Env

class ChatService:
    """
    ChatService is responsible for managing chat interactions.

    """

    def __init__(self) -> None:
        """
        Initialize the ChatService with an optional API key.

        Raises
        ------
        ValueError
            If the Google Gemini API key is not found in the environment.
        """
        # Check if Google API key is set in environment
        if not Env.GOOGLE_API_KEY:
            raise ValueError("Google Gemini API key not found in environment.")

        # Create chain components
        # Define the prompt template for the chat
        self.prompt: PromptTemplate = PromptTemplate(
            input_variables=["input", "history"],
            template="History: {history}\nUser: {input}\nAssistant:"
        )
        # Initialize the chat model with the specified language model and temperature
        self.llm: ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(model=Env.LANGUAGE_MODEL, temperature=0.7)
        # Create a conversation buffer memory to store the chat history
        self.memory: ConversationBufferMemory = ConversationBufferMemory()

        # Create the conversation chain using the defined components
        self.chain: ConversationChain = ConversationChain(
            llm=self.llm,
            memory=self.memory,
            prompt=self.prompt
        )
        # Alternative: create a simple LLM chain without memory
        # self.chain: LLMChain = LLMChain(llm=self.llm, prompt=self.prompt)


    def get_reply(self, prompt: str) -> str:
        """
        Takes user prompt and returns an LLM response using LangChain.

        Parameters
        ----------
        prompt: str
            The user's input prompt for the chat.

        Returns: str
            The response generated by the chat model.
        """
        # Check if the prompt is empty
        if not prompt:
            return "No prompt provided."

        # Run the conversation chain with the user's prompt and return the response
        return self.chain.run(input=prompt)
